
Observa â€” Model Inference & Monitoring

Observa is an end-to-end NLP + MLOps pipeline that demonstrates fine-tuned model inference, real-time monitoring, and experiment tracking â€” all integrated into one elegant web interface built with Gradio, FastAPI, Prometheus, Grafana, and MLflow.


Key Highlights


DVC Model versioning

ğŸ§© Fine-tuned DistilBERT model for text classification

ğŸ–¥ï¸ Gradio web interface (with FastAPI backend)

ğŸ“ˆ Prometheus metrics (/metrics endpoint)

ğŸ“Š Grafana dashboards for visualization

ğŸ§ª MLflow experiment tracking (loss, accuracy, artifacts)

ğŸ³ Dockerized for quick local or cloud deployment

ğŸ” Ready for OAuth integration and alerting (future scope)

Project Overview


          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚       Gradio UI          â”‚
          â”‚  (Model Inference Tab)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   FastAPI App    â”‚
             â”‚ exposes /metrics â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼               â–¼                        â–¼
 Prometheus      MLflow Server             Grafana
 (collects)      (tracks runs)             (visualizes)

```
```
Folder Structure

```

nlp-mlops-pipeline/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                     # Gradio + FastAPI app (Prometheus metrics + iframe embedding)
â”‚   â”œâ”€â”€ inference.py               # Hugging Face model + predict_with_threshold()
â”‚   â”œâ”€â”€ verify_model.py            # Utility to verify config.json and model files
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.app             # App container (Gradio + FastAPI)
â”‚   â”œâ”€â”€ Dockerfile.monitoring      # Prometheus + Grafana container
â”‚   â”œâ”€â”€ grafana-data/              # Grafana local data
â”‚   â”œâ”€â”€ prometheus-data/           # Prometheus local data
â”‚   â””â”€â”€ prometheus.render.yml      # Prometheus scrape configuration
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ grafana/                   # Grafana dashboards and configs
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”‚   â””â”€â”€ nlp-observa-dashboard.json
â”‚   â”‚   â”œâ”€â”€ datasources/
â”‚   â”‚   â”‚   â””â”€â”€ prometheus.yml
â”‚   â”‚   â””â”€â”€ grafana.ini
â”‚   â””â”€â”€ prometheus.yml             # Prometheus configuration (targets: app:7860/metrics)
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train.py                   # Model training with MLflow tracking
â”‚   â”œâ”€â”€ evaluate.py                # Evaluation script
â”‚   â”œâ”€â”€ params.yaml                # Configurable hyperparameters
â”‚   â””â”€â”€ data_prep.py               # Preprocessing logic
â”‚
â”œâ”€â”€ mlflow/
â”‚   â”œâ”€â”€ mlflow.db                  # Local tracking DB (if SQLite backend)
â”‚   â””â”€â”€ artifacts/                 # Stored MLflow runs and metrics
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ metrics.json               # Evaluation metrics summary


```
    
âš™ï¸ Local Setup

1ï¸âƒ£ Create Environment

```
python -m venv .venv
. .venv/Scripts/activate      # On Windows
# or source .venv/bin/activate (on Linux/Mac)
pip install -r app/requirements.txt

```

2ï¸âƒ£ Run the Application

```
python app/app.py


```

3ï¸âƒ£ (Optional) Run MLflow UI

```

mlflow ui --host 0.0.0.0 --port 5000


```

4ï¸âƒ£ (Optional) Run Prometheus and Grafana (Docker)


```

cd docker
docker compose up --build


```

ğŸ“ˆ Grafana Setup

ğŸ“ˆ Grafana Setup

1.Open Grafana at http://localhost:3000

2.Add a Prometheus data source â†’ URL: http://prometheus:9090

3.Import or create panels with queries like:

ğŸ§ª MLflow Experiment Tracking


Training scripts automatically log metrics and artifacts to MLflow.
If you want to use your own tracking server:

```
export MLFLOW_TRACKING_URI=http://localhost:5000

```

ğŸ§® Sample Output

Input:

```

UK markets rebound after inflation report

```
Output:

```
Prediction: Business (id 2)
Confidence: 95.38%
Latency: 1011 ms


```
ğŸ”§ Environment Variables

ğŸ“¦ Docker Deployment

```
docker compose up --build

```

Then visit:

App â†’ localhost:7860

Prometheus â†’ localhost:9090

Grafana â†’ localhost:3000

MLflow â†’ localhost:5000


ğŸ”­ Future Enhancements

Add OAuth-based login for dashboards

Integrate DVC for dataset versioning

Automate retraining and redeploy via CI/CD

Include Prometheus alerts for latency/error spikes

Add SHAP or LIME explainability inside Gradio UI

Deploy to cloud (Render / Oracle / AWS free tiers)



ğŸ§¾ License

MIT License Â© 2025 â€” Sandipan
Free to use and modify for educational and personal projects.






